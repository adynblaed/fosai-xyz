# What Terms Are Important?

# Key Terms in Machine Learning and Deep Learning

### 1. Activation Function
Activation functions decide whether a neuron should be activated or not. Examples include sigmoid, ReLU (Rectified Linear Units), and tanh (Hyperbolic tangent).

### 2. Artificial Neural Network (ANN)
Computational models inspired by the human brain. They consist of input and output layers, as well as (in most cases) a hidden layer consisting of units that transform the input into something the output layer can use.

### 3. Backpropagation
A method used in artificial neural networks to calculate the gradient of the loss function with respect to the weights.

### 4. Batch Size
The number of training examples used in one iteration of model training.

### 5. Bias-Variance Tradeoff
A fundamental concept in machine learning which states that models with a lower bias in training data tend to have higher variance in test data, and vice versa.

### 6. Convolutional Neural Network (CNN)
A type of deep learning model particularly well-suited for image classification tasks.

### 7. Dataset
A collection of data used in machine learning to train models. It usually consists of input features and corresponding target outputs (in the case of supervised learning).

### 8. Deep Learning (DL)
A subfield of machine learning that deals with algorithms inspired by the structure and function of the brain, called artificial neural networks.

### 9. Epoch
One complete pass through the entire training dataset while training a machine learning model.

### 10. Gradient Descent
An optimization algorithm used to minimize the loss function by iteratively moving in the direction of steepest descent, defined by the negative of the gradient.

### 11. Loss Function
A measure of how well a machine learning model is able to predict the expected outcome. It quantifies the difference between the predicted and actual outcomes.

### 12. Machine Learning (ML)
A field of artificial intelligence that uses statistical techniques to enable computer systems to 'learn' from data and improve performance on specific tasks.

### 13. Optimizer
The method used to adjust the parameters of a machine learning model to minimize the loss function. Examples include Stochastic Gradient Descent (SGD), Adam, and RMSprop.

### 14. Overfitting
A modeling error that occurs when a function fits the training data too closely and thus performs poorly on unseen data (test data).

### 15. Recurrent Neural Network (RNN)
A type of deep learning model often used for sequential data like time series or text.

### 16. Reinforcement Learning
A type of machine learning where an agent learns to behave in an environment, by performing certain actions and observing the results.

### 17. Supervised Learning
A type of machine learning where the model is provided with labeled training data.

### 18. Testing
The process where a trained machine learning model is applied to unseen data. This is used to gauge the model's performance.

### 19. Training
The process where a machine learning model 'learns' from the data. It iteratively adjusts its parameters on a given dataset to minimize a defined error function.

### 20. Underfitting
A modeling error that occurs when a function is too simplistic to capture the underlying structure of the data.

### 21. Unsupervised Learning
A type of machine learning where the model learns from data without any labels.
